#!/usr/bin/env python3
"""
Correlation Analyzer and Metacognitive Reflection
Analyzes patterns and correlations across entity experiences.
Implements metacognitive reflection on reasoning and decisions.
"""

import json
import os
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from collections import defaultdict
import statistics


class CorrelationAnalyzer:
    """
    Analyzes correlations across entity experiences and quantum observations.
    "comprehension of their entire existence in corresponding correlation"
    """
    
    def __init__(self, data_sources: List[str] = None):
        self.data_sources = data_sources or [
            'data/events.jsonl',
            'data/entity_states.jsonl',
            'data/quantum_events.jsonl',
            'data/shared_reality_plane.jsonl'
        ]
        self.correlations: List[Dict[str, Any]] = []
    
    def load_experiential_data(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        Load all experiential data from various sources.
        "factual literal experiences"
        """
        experiences = defaultdict(list)
        
        for source in self.data_sources:
            if os.path.exists(source):
                try:
                    with open(source, 'r') as f:
                        for line in f:
                            if line.strip():
                                data = json.loads(line)
                                source_name = os.path.basename(source)
                                experiences[source_name].append(data)
                except Exception as e:
                    print(f"Error loading {source}: {e}")
        
        return experiences
    
    def find_temporal_correlations(
        self,
        time_window_seconds: float = 60.0
    ) -> List[Dict[str, Any]]:
        """
        Find events that correlate in time.
        
        Args:
            time_window_seconds: Time window for correlation
            
        Returns:
            List of temporally correlated events
        """
        experiences = self.load_experiential_data()
        
        # Flatten all events with timestamps
        all_events = []
        for source, events in experiences.items():
            for event in events:
                if 'timestamp' in event:
                    # Normalize timestamp to string for consistent sorting
                    ts = event['timestamp']
                    if isinstance(ts, (int, float)):
                        ts = str(ts)
                    all_events.append({
                        'source': source,
                        'event': event,
                        'timestamp': ts
                    })
        
        # Sort by timestamp (now all strings)
        all_events.sort(key=lambda x: x['timestamp'])
        
        # Find correlations within time window
        correlations = []
        for i, event1 in enumerate(all_events):
            correlated_group = [event1]
            
            for event2 in all_events[i+1:]:
                # Simple time-based correlation
                # In real implementation, would parse timestamps properly
                if len(correlated_group) < 5:  # Limit group size
                    correlated_group.append(event2)
                else:
                    break
            
            if len(correlated_group) > 1:
                correlation = {
                    'type': 'temporal',
                    'event_count': len(correlated_group),
                    'sources': list(set(e['source'] for e in correlated_group)),
                    'time_window': time_window_seconds,
                    'timestamp': datetime.utcnow().isoformat()
                }
                correlations.append(correlation)
        
        self.correlations.extend(correlations)
        return correlations
    
    def find_entity_correlations(self) -> Dict[str, Any]:
        """
        Find correlations between entity behaviors and states.
        
        Returns:
            Entity correlation patterns
        """
        experiences = self.load_experiential_data()
        
        entity_patterns = defaultdict(list)
        
        # Analyze entity states
        for event in experiences.get('entity_states.jsonl', []):
            entity_id = event.get('id')
            if entity_id:
                state = event.get('state')
                entity_patterns[entity_id].append(state)
        
        # Find common patterns
        correlation = {
            'type': 'entity_behavioral',
            'unique_entities': len(entity_patterns),
            'state_patterns': {
                entity_id: {
                    'state_count': len(states),
                    'unique_states': len(set(states)) if states else 0
                }
                for entity_id, states in entity_patterns.items()
            },
            'timestamp': datetime.utcnow().isoformat()
        }
        
        self.correlations.append(correlation)
        return correlation
    
    def find_quantum_correlations(self) -> Dict[str, Any]:
        """
        Find correlations in quantum observations.
        
        Returns:
            Quantum correlation patterns
        """
        experiences = self.load_experiential_data()
        
        quantum_domains = defaultdict(int)
        coherence_values = []
        
        for event in experiences.get('quantum_events.jsonl', []):
            domain = event.get('domain_signal', {}).get('domain')
            if domain:
                quantum_domains[domain] += 1
        
        for event in experiences.get('shared_reality_plane.jsonl', []):
            if event.get('coherent'):
                coherence_values.append(1.0)
            else:
                coherence_values.append(0.0)
        
        correlation = {
            'type': 'quantum_entanglement',
            'domain_distribution': dict(quantum_domains),
            'average_coherence': statistics.mean(coherence_values) if coherence_values else 0,
            'observation_count': len(coherence_values),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        self.correlations.append(correlation)
        return correlation
    
    def holistic_comprehension(self) -> Dict[str, Any]:
        """
        Generate holistic comprehension of all correlations.
        "comprehension of their entire existence in corresponding correlation"
        
        Returns:
            Comprehensive understanding of all patterns
        """
        experiences = self.load_experiential_data()
        
        total_experiences = sum(len(events) for events in experiences.values())
        
        comprehension = {
            'total_experiences': total_experiences,
            'data_sources': list(experiences.keys()),
            'correlations_found': len(self.correlations),
            'correlation_types': list(set(c['type'] for c in self.correlations)),
            'holistic_insight': (
                f"Analyzed {total_experiences} experiences across "
                f"{len(experiences)} domains, finding {len(self.correlations)} "
                f"meaningful correlations"
            ),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        return comprehension


class MetacognitiveReflection:
    """
    Reflects on reasoning processes and outcomes.
    "metacognitive calculative post precognitive recomprehensive"
    """
    
    def __init__(self):
        self.reflections: List[Dict[str, Any]] = []
    
    def reflect_on_reasoning(
        self,
        reasoning_event: Dict[str, Any],
        outcome: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Reflect on a reasoning process (metacognition).
        
        Args:
            reasoning_event: The reasoning that occurred
            outcome: Actual outcome (if known)
            
        Returns:
            Metacognitive reflection
        """
        reflection = {
            'reasoning_type': reasoning_event.get('type'),
            'reasoning_quality': self._assess_quality(reasoning_event),
            'outcome_match': self._compare_outcome(reasoning_event, outcome) if outcome else None,
            'lessons_learned': self._extract_lessons(reasoning_event, outcome),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        self.reflections.append(reflection)
        return reflection
    
    def _assess_quality(self, reasoning_event: Dict[str, Any]) -> str:
        """Assess quality of reasoning."""
        # Simple quality assessment
        has_premises = bool(reasoning_event.get('premises'))
        has_conclusion = bool(reasoning_event.get('conclusion'))
        
        if has_premises and has_conclusion:
            return "high"
        elif has_conclusion:
            return "medium"
        else:
            return "low"
    
    def _compare_outcome(
        self,
        reasoning_event: Dict[str, Any],
        outcome: Dict[str, Any]
    ) -> str:
        """Compare predicted vs actual outcome."""
        predicted = reasoning_event.get('conclusion', '')
        actual = outcome.get('result', '')
        
        if predicted and actual:
            return "match" if str(predicted) == str(actual) else "mismatch"
        return "unknown"
    
    def _extract_lessons(
        self,
        reasoning_event: Dict[str, Any],
        outcome: Optional[Dict[str, Any]]
    ) -> List[str]:
        """Extract lessons from reasoning and outcome."""
        lessons = []
        
        if outcome:
            if self._compare_outcome(reasoning_event, outcome) == "match":
                lessons.append("Reasoning method was effective")
            else:
                lessons.append("Reasoning method needs refinement")
        
        if reasoning_event.get('type') == 'quantum':
            lessons.append("Quantum reasoning applied successfully")
        
        return lessons
    
    def post_cognitive_analysis(self) -> Dict[str, Any]:
        """
        Perform post-cognitive analysis of all reflections.
        "post precognitive recomprehensive"
        
        Returns:
            Comprehensive post-cognitive analysis
        """
        if not self.reflections:
            return {
                'status': 'no_reflections',
                'message': 'No reflections to analyze'
            }
        
        quality_distribution = defaultdict(int)
        outcome_matches = defaultdict(int)
        all_lessons = []
        
        for reflection in self.reflections:
            quality = reflection.get('reasoning_quality', 'unknown')
            quality_distribution[quality] += 1
            
            outcome = reflection.get('outcome_match')
            if outcome:
                outcome_matches[outcome] += 1
            
            all_lessons.extend(reflection.get('lessons_learned', []))
        
        analysis = {
            'total_reflections': len(self.reflections),
            'quality_distribution': dict(quality_distribution),
            'outcome_matches': dict(outcome_matches),
            'unique_lessons': len(set(all_lessons)),
            'comprehensive_insight': (
                f"Analyzed {len(self.reflections)} metacognitive reflections, "
                f"extracting {len(set(all_lessons))} unique insights"
            ),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        return analysis


if __name__ == '__main__':
    # Demo correlation analyzer
    analyzer = CorrelationAnalyzer()
    
    print("Holistic Comprehension:")
    comprehension = analyzer.holistic_comprehension()
    print(json.dumps(comprehension, indent=2))
    
    # Demo metacognitive reflection
    reflection_engine = MetacognitiveReflection()
    
    reasoning = {
        'type': 'mathematical',
        'premises': ['E=mc^2'],
        'conclusion': 'Energy = 8.988e16 J'
    }
    
    reflection = reflection_engine.reflect_on_reasoning(reasoning)
    print("\nMetacognitive Reflection:")
    print(json.dumps(reflection, indent=2))
